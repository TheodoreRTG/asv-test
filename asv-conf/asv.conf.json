{
    // The version of the config file format.  Do not change, unless
    // you know what you are doing.
    "version": 1,

    // The name of the project being benchmarked
    "project": "tensorflow",

    // The project's homepage
    "project_url": "http://project-homepage.org",

    // The URL or local path of the source code repository for the
    // project being benchmarked
    "repo": "http://github.com/tensorflow/tensorflow.git",
//    "repo": "/home/theodore/plusinf/tensorflow/",
    // The Python project's subdirectory in your repo.  If missing or
    // the empty string, the project is assumed to be located at the root
    // of the repository.
    //    "repo_subdir": "tensorflow/python/pip_package",

    // Customizable commands for building, installing, and
    // uninstalling the project. See asv.conf.json documentation.
    //
     "install_command": [ "in-dir=/root/asv-test/ python3 -m pip install ck --no-cache", "in-dir=/root/asv-test/ python3 -m pip install --no-binary pycocotools pycocotools --no-cache", "in-dir=/root/asv-test/ python3 -m pip install absl-py pillow --no-cache", "in-dir=/root/asv-test python3 -m pip install --extra-index-url https://snapshots.linaro.org/ldcg/python-cache/ numpy --no-cache", "in-dir=/root/asv-test/ python3 -m pip install --extra-index-url https://snapshots.linaro.org/ldcg/python-cache/ matplotlib --no-cache", "in-dir=/root/asv-test/ python3 -m pip install --extra-index-url https://snapshots.linaro.org/ldcg/python-cache/ tensorflow-io-gcs-filesystem==0.24.0 h5py==3.1.0 --no-cache"],
     "uninstall_command": ["return-code=any python -mpip uninstall -y tensorflow-aarch64", "return-code=any python -mpip uninstall -y pycocotools", "return-code=any python -mpip uninstall -y absl-py pillow", "return-code=any python -mpip uninstall -y numpy==1.19.5", "return-code=any python -mpip uninstall -y matplotlib", "return-code=any python -mpip uninstall -y tensorflow-io-gcs-filesystem==0.24.0 h5py==3.1.0"],
      //"build_command": ["PIP_NO_BUILD_ISOLATION=false python3 -mpip install -v tensorflow-aarch64==2.8.2 "],
     "build_command": ["PIP_NO_BUILD_ISOLATION=false in-dir=/root/asv-test/asv-conf python3 -m pip install -v tensorflow_aarch64-2.11.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl --no-cache"],

    // List of branches to benchmark. If not provided, defaults to "master"
    // (for git) or "default" (for mercurial).
    //"branches": ["main"], // for git
    // "branches": ["default"],    // for mercurial

    // The DVCS being used.  If not set, it will be automatically
    // determined from "repo" by looking at the protocol in the URL
    // (if remote), or by looking for special directories, such as
    // ".git" (if local).
    // "dvcs": "git",

    // The tool to use to create environments.  May be "conda",
    // "virtualenv" or other value depending on the plugins in use.
    // If missing or the empty string, the tool will be automatically
    // determined by looking for tools on the PATH environment
    // variable.
    "environment_type": "virtualenv",

    // timeout in seconds for installing any dependencies in environment
    // defaults to 10 min
    "install_timeout": 1200,

    // the base URL to show a commit for the project.
    // "show_commit_url": "http://github.com/owner/project/commit/",

    // The Pythons you'd like to test against.  If not provided, defaults
    // to the current version of Python used to run `asv`.
     //"pythons": ["3.9.2"],

    // The list of conda channel names to be searched for benchmark
    // dependency packages in the specified order
    // "conda_channels": ["conda-forge", "defaults"],

    // A conda environment file that is used for environment creation.
    // "conda_environment_file": "environment.yml",

    // The matrix of dependencies to test.  Each key of the "req"
    // requirements dictionary is the name of a package (in PyPI) and
    // the values are version numbers.  An empty list or empty string
    // indicates to just test against the default (latest)
    // version. null indicates that the package is to not be
    // installed. If the package to be tested is only available from
    // PyPi, and the 'environment_type' is conda, then you can preface
    // the package name by 'pip+', and the package will be installed
    // via pip (with all the conda available packages installed first,
    // followed by the pip installed packages).
    //
    // The ``@env`` and ``@env_nobuild`` keys contain the matrix of
    // environment variables to pass to build and benchmark commands.
    // An environment will be created for every combination of the
    // cartesian product of the "@env" variables in this matrix.
    // Variables in "@env_nobuild" will be passed to every environment
    // during the benchmark phase, but will not trigger creation of
    // new environments.  A value of ``null`` means that the variable
    // will not be set for the current combination.
    //
    // "matrix": {
    //     "req": {
    //         "numpy": ["1.6", "1.7"],
    //         "six": ["", null],  // test with and without six installed
    //         "pip+emcee": [""]   // emcee is only available for install with pip.
    //     },
    //     "env": {"ENV_VAR_1": ["val1", "val2"]},
    //     "env_nobuild": {"ENV_VAR_2": ["val3", null]},
    // },


    
     "matrix": {
         "req": {
      //       "numpy": ["1.6", "1.7"],
            "wheel": [""],  // test with and without six installed
	    "h5py": [""],
	    "cython": [""],
	    "google": [""],
            "protobuf": [""],
	   // "tensorflow-aarch64": [""],
	 //   "tensorflow-aarch64": ["2.9.1", "2.8.2", "2.7.0"],
//	    "pycocotools": [""],
//	    "absl-py": [""],
	    "pillow": [""],
//            "numpy": ["1.19.5"],
//	    "matplotlib": [""],
//	    "ck": [""],
	    "scikit-build": [""]
	      //       "pip+emcee": [""]   // emcee is only available for install with pip.
         },
    //     "env": {"ENV_VAR_1": ["val1", "val2"]},
    //     "env_nobuild": {"ENV_VAR_2": ["val3", null]},
     },

    // Combinations of libraries/python versions can be excluded/included
    // from the set to test. Each entry is a dictionary containing additional
    // key-value pairs to include/exclude.
    //
    // An exclude entry excludes entries where all values match. The
    // values are regexps that should match the whole string.
    //
    // An include entry adds an environment. Only the packages listed
    // are installed. The 'python' key is required. The exclude rules
    // do not apply to includes.
    //
    // In addition to package names, the following keys are available:
    //
    // - python
    //     Python version, as in the *pythons* variable above.
    // - environment_type
    //     Environment type, as above.
    // - sys_platform
    //     Platform, as in sys.platform. Possible values for the common
    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.
    // - req
    //     Required packages
    // - env
    //     Environment variables
    // - env_nobuild
    //     Non-build environment variables
    //
    // "exclude": [
    //     {"python": "3.2", "sys_platform": "win32"}, // skip py3.2 on windows
    //     {"environment_type": "conda", "req": {"six": null}}, // don't run without six on conda
    //     {"env": {"ENV_VAR_1": "val2"}}, // skip val2 for ENV_VAR_1
    // ],
    //
    // "include": [
    //     // additional env for python2.7
    //     {"python": "2.7", "req": {"numpy": "1.8"}, "env_nobuild": {"FOO": "123"}},
    //     // additional env if run on windows+conda
    //     {"platform": "win32", "environment_type": "conda", "python": "2.7", "req": {"libpython": ""}},
    // ],

    // The directory (relative to the current directory) that benchmarks are
    // stored in.  If not provided, defaults to "benchmarks"
    // "benchmark_dir": "benchmarks",

    // The directory (relative to the current directory) to cache the Python
    // environments in.  If not provided, defaults to "env"
    //"env_dir": ".asv/mobilenet",

    // The directory (relative to the current directory) that raw benchmark
    // results are stored in.  If not provided, defaults to "results".
    //"results_dir": ".asv/results-mobilenet",

    // The directory (relative to the current directory) that the html tree
    // should be written to.  If not provided, defaults to "html".
    //"html_dir": ".asv/html-mobilenet",

    // The number of characters to retain in the commit hashes.
    // "hash_length": 8,

    // `asv` will cache results of the recent builds in each
    // environment, making them faster to install next time.  This is
    // the number of builds to keep, per environment.
    // "build_cache_size": 2,

    // The commits after which the regression search in `asv publish`
    // should start looking for regressions. Dictionary whose keys are
    // regexps matching to benchmark names, and values corresponding to
    // the commit (exclusive) after which to start looking for
    // regressions.  The default is to start from the first commit
    // with results. If the commit is `null`, regression detection is
    // skipped for the matching benchmark.
    //
    // "regressions_first_commits": {
    //    "some_benchmark": "352cdf",  // Consider regressions only after this commit
    //    "another_benchmark": null,   // Skip regression detection altogether
    // },

    // The thresholds for relative change in results, after which `asv
    // publish` starts reporting regressions. Dictionary of the same
    // form as in ``regressions_first_commits``, with values
    // indicating the thresholds.  If multiple entries match, the
    // maximum is taken. If no entry matches, the default is 5%.
    //
    // "regressions_thresholds": {
    //    "some_benchmark": 0.01,     // Threshold of 1%
    //    "another_benchmark": 0.5,   // Threshold of 50%
    // },
}
